{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "774def3b-8e34-45c2-a90d-320e7fb26120",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from CrossSecPlotter import *\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "RANDSTATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c18ac44-325f-464f-b27e-d234efff1762",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset():\n",
    "    def __init__(self, train_X, valid_X, train_y, valid_y, X_test = None):\n",
    "        self.X_train = train_X\n",
    "        self.y_train = train_y\n",
    "        self.X_valid = valid_X\n",
    "        self.y_valid = valid_y\n",
    "        self.X_test = X_test\n",
    "        \n",
    "        self.normalized = False\n",
    "        \n",
    "    def __str__(self):\n",
    "        return str((self.train_X.shape, self.train_y.shape, self.valid_X.shape, self.valid_y.shape))\n",
    "\n",
    "    def normalize(self):\n",
    "        if self.normalized:\n",
    "            print(\"already normalized!\")\n",
    "            return\n",
    "        \n",
    "        std_list = np.std(self.X_train, axis=0)\n",
    "        std_list = np.where(std_list == 0, 1, std_list) # prevent zero division error\n",
    "        avg_list = np.mean(self.X_train, axis=0)\n",
    "        self.X_train = (self.X_train - avg_list)/std_list\n",
    "        if not self.X_valid is None: self.X_valid = (self.X_valid - avg_list)/std_list\n",
    "        if not self.X_test is None: self.X_test = (self.X_test - avg_list)/std_list\n",
    "            \n",
    "        self.std_list = std_list\n",
    "        self.avg_list = avg_list\n",
    "        print(\"dataset normalized!\")\n",
    "        self.normalized = True\n",
    "        return\n",
    "    \n",
    "    def normalize_vec(self, X):\n",
    "        if not self.normalized:\n",
    "            print(\"Dataset never normalized\")\n",
    "        return (X - self.avg_list)/self.std_list\n",
    "    \n",
    "    def add_fict(self):\n",
    "        add_ones = lambda X: np.hstack((X,np.ones((X.shape[0],1))))\n",
    "        self.X_train = add_ones(self.X_train)\n",
    "        self.X_valid = add_ones(self.X_valid)\n",
    "        self.X_test = add_ones(self.X_test)\n",
    "        print(\"ficticious dimension added!\")\n",
    "        \n",
    "    def print_dim(self):\n",
    "        print(\"X_train has shape:\",self.X_train.shape)\n",
    "        print(\"y_train has shape:\",self.y_train.shape)\n",
    "        print(\"X_valid has shape:\",self.X_valid.shape)\n",
    "        print(\"y_valid has shape:\",self.y_valid.shape)\n",
    "        if self.X_test: print(\"X_test has shape:\",self.X_test.shape)\n",
    "\n",
    "def plot_acc(xl, yl, zl, filename, title):\n",
    "    plt.plot(xl, yl, label=\"validation\")\n",
    "    plt.plot(xl, zl, label=\"training\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"number of training data points\")\n",
    "    plt.ylabel(\"accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86b9c85d-5221-434f-9134-a7a4fe3bd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadXy(data_dir):\n",
    "    with open(data_dir, \"rb\") as fp:   # Unpickling\n",
    "        data_list = pickle.load(fp)\n",
    "\n",
    "    xpts, ypts, zpts, _, magpts = data_list\n",
    "\n",
    "    # check data\n",
    "    assert(len(xpts)==len(ypts) and len(xpts)==len(zpts) and len(xpts)==len(magpts))\n",
    "\n",
    "    # Transform the data into X, y form\n",
    "    n = len(xpts)\n",
    "    d = 3\n",
    "    X = np.array([xpts, ypts, zpts]).T\n",
    "    y = np.array(magpts)\n",
    "    return X, y\n",
    "def load_train(exp_num, withStability, verbose=3, datafolder = \"Data/\"):\n",
    "    datafile = \"data%d.pkl\"%exp_num if not withStability else \"data%d(withStability).pkl\"%exp_num\n",
    "    datafile = datafolder + datafile\n",
    "\n",
    "    X, y = loadXy(datafile)\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.3, random_state=41) #!!! RANDSEED\n",
    "    venus = MyDataset(X_train, X_valid, y_train, y_valid)\n",
    "    if verbose&1:\n",
    "        print(\"run %d data loaded!\"%exp_num)\n",
    "        venus.print_dim()\n",
    "        venus.normalize()\n",
    "    \n",
    "    alpha = 0.15 # best value is 0.15\n",
    "    kernel = Matern(nu=0.66)\n",
    "    # kernel = RBF() #\n",
    "\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel, random_state=0, alpha=alpha).fit(venus.X_train, venus.y_train)\n",
    "\n",
    "    # check\n",
    "    if verbose&2:\n",
    "        print(\"Experiment %d  \"%exp_num)\n",
    "        print(\"With Stability:\", withStability,\"  \")\n",
    "        print(\"Train score: %f  \"%gpr.score(venus.X_train, venus.y_train))\n",
    "        print(\"Test score:  %f  \"%gpr.score(venus.X_valid, venus.y_valid))\n",
    "    \n",
    "    return venus, gpr, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e07aeaab-ffa3-4a0a-b582-e8f7a270bf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a model for all data\n",
    "# for exp_num in range(1,3):\n",
    "#     for withStability in [True, False]:\n",
    "#         load_train(exp_num, withStability, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b0eeab0-f173-40b9-9aed-852b624331e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run 1 data loaded!\n",
      "X_train has shape: (271, 3)\n",
      "y_train has shape: (271,)\n",
      "X_valid has shape: (117, 3)\n",
      "y_valid has shape: (117,)\n",
      "dataset normalized!\n",
      "Experiment 1  \n",
      "With Stability: True   \n",
      "Train score: 0.969555  \n",
      "Test score:  0.762494  \n"
     ]
    }
   ],
   "source": [
    "exp_num = 1\n",
    "withStability = True\n",
    "\n",
    "venus, gpr, X, y = load_train(exp_num, withStability)\n",
    "alpha = 0.15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c379848c-f027-4108-988f-4e0b0102c14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matern nu tuning\n",
    "# cv_score = []\n",
    "# nus = np.linspace(0.4, 2.6, 3)\n",
    "# relu = lambda x: x if x>0 else 0\n",
    "# for nu in nus:\n",
    "#     kernel = Matern(nu=nu)\n",
    "#     gpr = GaussianProcessRegressor(kernel=kernel,random_state=0, alpha=alpha).fit(venus.X_train, venus.y_train)\n",
    "#     cvs = cross_val_score(gpr, X, y)\n",
    "#     avg_cvs = sum(cvs)/len(cvs)\n",
    "#     print(\"%f for nu=%f\"%(avg_cvs, nu))\n",
    "#     cv_score.append(avg_cvs)\n",
    "\n",
    "# cv_score = [relu(x) for x in cv_score]\n",
    "# plt.plot(nus, cv_score, label=\"Cross-Validation Score\")\n",
    "# plt.legend()\n",
    "# plt.xlabel(\"nu\")\n",
    "# plt.title(\"Matern Kernel (alpha = 0.15)\")\n",
    "# plt.savefig(\"Matern nu.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdb55c6d-5d52-49e9-aa55-af88aaef4932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset normalized!\n",
      "Whole dataset training score: 0.972226\n"
     ]
    }
   ],
   "source": [
    "# use all available data for the final model\n",
    "kernel = Matern(nu=0.66)\n",
    "\n",
    "\n",
    "venus_whole = MyDataset(X, None, y, None)\n",
    "venus_whole.normalize()\n",
    "\n",
    "gpr = GaussianProcessRegressor(kernel=kernel,random_state=1, alpha=alpha).fit(venus_whole.X_train, venus_whole.y_train)\n",
    "print(\"Whole dataset training score: %f\"%gpr.score(venus_whole.X_train, venus_whole.y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e5afd43-2c47-4a5f-b73f-59b73f04e4bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102.52640418 104.08696283 122.59401936] [3.34305675 3.45653727 3.00584971]\n"
     ]
    }
   ],
   "source": [
    "# save the model and print the normalizing lists used\n",
    "with open(\"Models/gprMatern0.66.dump\" , \"wb\") as f:\n",
    "    pickle.dump(gpr, f)\n",
    "print(venus_whole.avg_list, venus_whole.std_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9909c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize_gpr(gpr, dataset):\n",
    "    \"\"\"Denormalize and unpack gpr into a mean function and a variance function. \"\"\"\n",
    "    def gauss_mean(x, y, z):\n",
    "        arr = np.array([[x,y,z]])\n",
    "        arr = dataset.normalize_vec(arr)\n",
    "        result = gpr.predict(arr)\n",
    "        return result\n",
    "    \n",
    "    def gauss_var(x, y, z):\n",
    "        arr = np.array([[x,y,z]])\n",
    "        arr = dataset.normalize_vec(arr)\n",
    "        result = gpr.predict(arr, return_std=True)[1]\n",
    "        return result\n",
    "    return gauss_mean, gauss_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad546468-348c-4efa-86d8-31ee993aeb7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cross Sections.gif'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gauss_mean, gauss_var = denormalize_gpr(gpr, venus_whole)\n",
    "\n",
    "z_values = np.linspace(117, 130, 27)\n",
    "plot_4D(gauss_mean, z_values, \"Figures/GPRplots/mean_refact/\", color_num = 21, wbounds=(0, 170))\n",
    "# plot_4D(gauss_var, z_values, \"Figures/GPRplots/var_refact/\", color_num = 21, wbounds=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dbd47a4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'test.gif.gif'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# plot_4D_CS(gauss_mean, 126, wbounds=(0, 170))\n",
    "plot_4D(gauss_mean, z_values, func_name=\"test\",save_images=False, color_num = 21, wbounds=(0, 170))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee288dc2-6f88-481e-b05c-2b6c3c125c22",
   "metadata": {},
   "source": [
    "# Compare the Normalized Results of the two runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "155e2e12-4bdf-4d8a-b782-dce99a3907a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset normalized!\n",
      "Whole dataset training score: 0.972426\n",
      "dataset normalized!\n",
      "Whole dataset training score: 0.956383\n"
     ]
    }
   ],
   "source": [
    "# train two models\n",
    "\n",
    "def train_model_on_run(data_dir):\n",
    "    X, y = loadXy(data_dir)\n",
    "    venus_whole = MyDataset(X, None, y, None)\n",
    "    venus_whole.normalize()\n",
    "\n",
    "    kernel = Matern(nu=0.66)\n",
    "    gpr = GaussianProcessRegressor(kernel=kernel,random_state=1, alpha=alpha).fit(venus_whole.X_train, venus_whole.y_train)\n",
    "    print(\"Whole dataset training score: %f\"%gpr.score(venus_whole.X_train, venus_whole.y_train))\n",
    "    return gpr, venus_whole\n",
    "\n",
    "gpr1, venus1 = train_model_on_run(\"Data/data1.pkl\")\n",
    "gpr2, venus2 = train_model_on_run(\"Data/data2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76d17789-6cfe-4304-9011-fea138bf966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for z in np.linspace(117, 130, 27):\n",
    "#     plot_cross_section(gpr1, z, dataset=venus1, plotVar=True)\n",
    "#     plot_cross_section(gpr1, z, dataset=venus1, plotVar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b90102c5-67b0-4caa-b5db-e21e2b80a187",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames1 = []\n",
    "filenames2 = []\n",
    "for z in np.linspace(117, 130, 27):\n",
    "    filenames1.append(plot_cross_section(gpr2, z, dataset=venus2, plotVar=True))\n",
    "    filenames2.append(plot_cross_section(gpr2, z, dataset=venus2, plotVar=False, z_ratio=0.87)) # , \n",
    "    \n",
    "\n",
    "with imageio.get_writer('mygif.gif', mode='I') as writer:\n",
    "    for filename in filenames1:\n",
    "        image = imageio.imread(filename)\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c0d66c-7f4e-41ec-a01c-86df2d78f1d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('LBNL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8f9c2828888885c68fe31a37e7fd660674c95c752917f33df47da5807bff37a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan (end of 2022)\n",
    "- Other parameters: Sextapole, rf power. Finally oven parameters. \n",
    "\n",
    "    Should be able to just add them. Need the scaling function for new variables. \n",
    "\n",
    "- Guide the optimization.\n",
    "\n",
    "    ```\n",
    "    optimizer.probe(params)\n",
    "    ```\n",
    "\n",
    "- Avoid **danger zone** by monitoring the heater power.\n",
    "\n",
    "    > x-ray -> temp of heliem -> amount of gas -> pressure -> ice -> liquid heliem heater power (final diagnosis of x-ray). We really want to avoid x-rays\n",
    "\n",
    "    Add heater power to `venus.monitor()` and implement `venus.get_heater_power()`\n",
    "    ```python\n",
    "    def black_box_function(A, B, C):\n",
    "        venus.set_mag_currents(A, B, C)\n",
    "        ...\n",
    "        while time.time() < t_end:\n",
    "            venus.monitor(t_start,t_program_start,writefile,readvars,writefilefull)\n",
    "            if venus.get_heater_power() > threshold:\n",
    "                #TODO: reset the parameters\n",
    "                return - xray_cost\n",
    "        ...\n",
    "\n",
    "        #Monitor while measuring the beam current\n",
    "        return v_mean - instability_cost\n",
    "    ```\n",
    "\n",
    "- Consider \"momentum\". Early ending. \n",
    "\n",
    "    > Bias disk is fastest. Solonoid has induction. Gas pressure. \n",
    "\n",
    "    Modify the accquisition function of Bayes Optimization.\n",
    "\n",
    "    ```python\n",
    "    def _ucb(x, gp, kappa):\n",
    "        ...\n",
    "        return mean + kappa * std\n",
    "    ```\n",
    "\n",
    "    ```python\n",
    "    def _ucb(x, gp, kappa):\n",
    "        ...\n",
    "        return mean + kappa * std - np.dot(epsilon, displacement)\n",
    "        # epsilon and displacement are dim-d vectors in the parameter space\n",
    "    ```\n",
    "\n",
    "    simulate:\n",
    "    assume t1 = d * c1\n",
    "    inj 30s/uA\n",
    "    ext 20s/uA\n",
    "    mid 10s/uA\n",
    "\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2023.1.6 "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking varying cost into account in Bayes Optimization\n",
    "- Expected Improvement (EI) is more commonly used than Upper Confidence Bound (UCB) as an acquisition function and has some theortical basis for convergence [Vazquez et al., 2010](https://www.sciencedirect.com/science/article/pii/S0378375810001850). \n",
    "    $$EI(x)=\\mathbb{E} [max(f(x)−f(x_+),0) ]$$\n",
    "    where $f$ is the model, $x_+$ is the current best parameter. \n",
    "    \n",
    "    Sometimes a term is added to facilitate exploration:\n",
    "    $$EI(x)=\\mathbb{E} [max(f(x)−f(x_+)-\\xi,0) ]$$\n",
    "    [Krasser, 2018](http://krasserm.github.io/2018/03/21/bayesian-optimization/#:~:text=A%20recommended%20default,.) recommended $\\xi$ to be 0.01 but this seems arbitrary to me and other papers have been using $\\xi=0$ so we could ignore this term for now. \n",
    "- Expected Improvement Per Unit cost [Snoek et al., 2012](https://papers.nips.cc/paper/2012/file/05311655a15b75fab86956663e1819cd-Paper.pdf)\n",
    "    $$EIpu(x) = \\frac{EI(x)}{c(x)}$$\n",
    "    \n",
    "- The problem with EIPU in the context of ML is that model training cost $c$ is fixed so it doesn't necessarilly converge to the best parameters. [Lee et al., 2020](https://assets.amazon.science/53/43/5121e84a45c7965cfd0644d81ec1/cost-aware-bayesian-optimization.pdf) proposed adding a **cost-cooled optimization phase** \n",
    "    \n",
    "    However, in our case, $EIpu(x_{i+1})$ is going to change based on where we probed last. A better way to write it is $EIpu(x_{i+1};x_i)$\n",
    "    \n",
    "    It is also meaningful (the expected amount of improvement per unit time spent) and is a great indicator for terminating the search. \n",
    "\n",
    "### Initial Probing\n",
    "- Draw 4 random points $\\mathcal{N}(0, I_d)$ around the best parameters found last time. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coding notes:\n",
    "\n",
    "- Finished changing acquisition function from UCB to EI and tested. Performance increased slightly (about 0.5%). \n",
    "- Fixed bug in parameter ordering\n",
    "\n",
    "### Meeting notes:\n",
    "- Use h5 files with better data. Can be found on google drive. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meeting Notes 2023.1.13\n",
    "\n",
    "Milestone: 6 parameters\n",
    "\n",
    "Data from Damon\n",
    "\n",
    "Start writting the paper without the milestone"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Literature Search 2023.1.19"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make some graphs like the ones used in [Toward Machine Learning Optimization of Experimental Design](https://www.tandfonline.com/doi/full/10.1080/10619127.2021.1881364?casa_token=Acw7p8D6GgwAAAAA%3A8JegBh69OQFyzndVx3Iy53wLvwStcm-9R9yXjBYyY137RKNaAfAcc_SBXVYySnpTyRLiTqfycu4f6mU)\n",
    "\n",
    "\"Cold atom experiments are increasingly complex and time consuming to optimize\" [Evolutionary optimization of an experimental apparatus](https://aip.scitation.org/doi/full/10.1063/1.4808213?casa_token=2liBRG6XON0AAAAA%3A3Ab3NaXaHUvtBJALYJXjjqyXFznSKmcKhDzRbTiQP5kD4PzI8HO7TwiPOxzWNa3SOsvXu2au3_yjtw). The first few sentence in this abstract is basically our motivation for doing this project. BUT their algorithm (DE) is vastly less sample efficient.\n",
    "\n",
    "[Fast machine-learning online optimization of ultra-cold-atom experiments](https://www.nature.com/articles/srep25890?ref=https://githubhelp.com) Nature Scientific Reports 2016. Similar to our approach, but used some weird hypothesis testing ideas. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finished acquisition change in the library and pull-requested\n",
    "- Finished literature search\n",
    "- Started writing the paper\n",
    "- Settling time:  \n",
    " qualitatively, it looks like there is no clear relation between $\\delta$ and settlement time in most parameters except the coils?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO 2023.2.10\n",
    "Compare to Random, EI, EIPU. Time it cost to reach 10% of best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LBNL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b8f9c2828888885c68fe31a37e7fd660674c95c752917f33df47da5807bff37a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
